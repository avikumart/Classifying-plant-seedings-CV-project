{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nimport cv2\nimport zipfile\nimport os\nimport glob\nimport shutil\nfrom sklearn.utils import shuffle\n\nimport tensorflow as tf\nimport keras\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import (Conv2D, MaxPooling2D, Flatten, Dense, \n                          Dropout, Rescaling, RandomFlip, RandomRotation, BatchNormalization)\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-09T13:22:45.366993Z","iopub.execute_input":"2023-02-09T13:22:45.367665Z","iopub.status.idle":"2023-02-09T13:22:51.401583Z","shell.execute_reply.started":"2023-02-09T13:22:45.367529Z","shell.execute_reply":"2023-02-09T13:22:51.400445Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Loading the dataset","metadata":{}},{"cell_type":"code","source":"# print the list of labels in folder\nfolder_path = '/kaggle/input/imageclassificationdataset'\nlabels = os.listdir(folder_path)\nlabels","metadata":{"execution":{"iopub.status.busy":"2023-02-09T13:22:51.403581Z","iopub.execute_input":"2023-02-09T13:22:51.404313Z","iopub.status.idle":"2023-02-09T13:22:51.436309Z","shell.execute_reply.started":"2023-02-09T13:22:51.404270Z","shell.execute_reply":"2023-02-09T13:22:51.432367Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"['Scentless Mayweed',\n 'Common wheat',\n 'Charlock',\n 'Black-grass',\n 'Sugar beet',\n 'Loose Silky-bent',\n 'Maize',\n 'Cleavers',\n 'Common Chickweed',\n 'Fat Hen',\n 'Small-flowered Cranesbill',\n 'Shepherd’s Purse']"},"metadata":{}}]},{"cell_type":"code","source":"# path to Black grass images\npath = '/kaggle/input/imageclassificationdataset/Black-grass'\n\nimages = os.listdir(path)\nlen(images)","metadata":{"execution":{"iopub.status.busy":"2023-02-09T13:22:51.440633Z","iopub.execute_input":"2023-02-09T13:22:51.445352Z","iopub.status.idle":"2023-02-09T13:22:51.502143Z","shell.execute_reply.started":"2023-02-09T13:22:51.445311Z","shell.execute_reply":"2023-02-09T13:22:51.500438Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"309"},"metadata":{}}]},{"cell_type":"code","source":"label_count = {}\n\n# path to images folders \nnpath = '/kaggle/input/imageclassificationdataset/'\n\n# run a for loop on labels\nfor label in labels:\n    images_num = len(os.listdir(npath + label))\n    label_count[label] = images_num\n    \nlabel_count","metadata":{"execution":{"iopub.status.busy":"2023-02-09T13:22:51.510367Z","iopub.execute_input":"2023-02-09T13:22:51.511051Z","iopub.status.idle":"2023-02-09T13:22:52.230887Z","shell.execute_reply.started":"2023-02-09T13:22:51.511012Z","shell.execute_reply":"2023-02-09T13:22:52.229954Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"{'Scentless Mayweed': 607,\n 'Common wheat': 253,\n 'Charlock': 452,\n 'Black-grass': 309,\n 'Sugar beet': 463,\n 'Loose Silky-bent': 762,\n 'Maize': 257,\n 'Cleavers': 335,\n 'Common Chickweed': 713,\n 'Fat Hen': 538,\n 'Small-flowered Cranesbill': 576,\n 'Shepherd’s Purse': 274}"},"metadata":{}}]},{"cell_type":"code","source":"# find the total number of  images\nimages_count = 0\nfor value in label_count.values():\n    images_count += value\n    \nprint(images_count)","metadata":{"execution":{"iopub.status.busy":"2023-02-09T13:22:52.232172Z","iopub.execute_input":"2023-02-09T13:22:52.232547Z","iopub.status.idle":"2023-02-09T13:22:52.238810Z","shell.execute_reply.started":"2023-02-09T13:22:52.232504Z","shell.execute_reply":"2023-02-09T13:22:52.237802Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"5539\n","output_type":"stream"}]},{"cell_type":"code","source":"# class labels\nclass_names = ['Scentless Mayweed',\n 'Common wheat',\n 'Charlock',\n 'Black-grass',\n 'Sugar beet',\n 'Loose Silky-bent',\n 'Maize',\n 'Cleavers',\n 'Common Chickweed',\n 'Fat Hen',\n 'Small-flowered Cranesbill',\n 'Shepherd’s Purse']\n\n\nclass_labels = {class_name:i for i, class_name in enumerate(class_names)}\nprint(class_labels)\n\nIMAGE_SIZE = (120,120)","metadata":{"execution":{"iopub.status.busy":"2023-02-09T13:22:52.240108Z","iopub.execute_input":"2023-02-09T13:22:52.240765Z","iopub.status.idle":"2023-02-09T13:22:52.250999Z","shell.execute_reply.started":"2023-02-09T13:22:52.240729Z","shell.execute_reply":"2023-02-09T13:22:52.249759Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"{'Scentless Mayweed': 0, 'Common wheat': 1, 'Charlock': 2, 'Black-grass': 3, 'Sugar beet': 4, 'Loose Silky-bent': 5, 'Maize': 6, 'Cleavers': 7, 'Common Chickweed': 8, 'Fat Hen': 9, 'Small-flowered Cranesbill': 10, 'Shepherd’s Purse': 11}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Labeling the dataset","metadata":{}},{"cell_type":"code","source":"# labeling the dataset\nlabelled_data = []\n\nimages1 = []\nlabels1 = []\n\n\nfor label in labels:\n    lab = class_labels[label]\n    for img in os.listdir(os.path.join('/kaggle/input/imageclassificationdataset/', label)):\n        image_path = os.path.join(os.path.join(npath, label), img)\n        # read the image files\n        img_file = cv2.imread(image_path)\n        img_file = cv2.cvtColor(img_file, cv2.COLOR_BGR2RGB)\n        img_file = cv2.resize(img_file, IMAGE_SIZE)\n        \n        images1.append(img_file)\n        labels1.append(lab)","metadata":{"execution":{"iopub.status.busy":"2023-02-09T13:22:52.252675Z","iopub.execute_input":"2023-02-09T13:22:52.253440Z","iopub.status.idle":"2023-02-09T13:23:57.654271Z","shell.execute_reply.started":"2023-02-09T13:22:52.253400Z","shell.execute_reply":"2023-02-09T13:23:57.648875Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# convert data into np array\nimages1 = np.array(images1, dtype='float32')\nlabels1 = np.array(labels1, dtype='int32')","metadata":{"execution":{"iopub.status.busy":"2023-02-09T13:23:57.655562Z","iopub.execute_input":"2023-02-09T13:23:57.656145Z","iopub.status.idle":"2023-02-09T13:23:57.937277Z","shell.execute_reply.started":"2023-02-09T13:23:57.656104Z","shell.execute_reply":"2023-02-09T13:23:57.936314Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# shuffle the train nad test datasets\n(images1, labels1) = shuffle(images1, labels1, random_state=45)","metadata":{"execution":{"iopub.status.busy":"2023-02-09T13:23:57.938704Z","iopub.execute_input":"2023-02-09T13:23:57.939321Z","iopub.status.idle":"2023-02-09T13:23:58.236382Z","shell.execute_reply.started":"2023-02-09T13:23:57.939284Z","shell.execute_reply":"2023-02-09T13:23:58.235339Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# normalize the iamges\nimages_norm = images1/255.0","metadata":{"execution":{"iopub.status.busy":"2023-02-09T13:23:58.240556Z","iopub.execute_input":"2023-02-09T13:23:58.241179Z","iopub.status.idle":"2023-02-09T13:23:58.523603Z","shell.execute_reply.started":"2023-02-09T13:23:58.241143Z","shell.execute_reply":"2023-02-09T13:23:58.522592Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# train and test split\ntrain_images = images1[:4500]\ntrain_labels = labels1[:4500]\n\ntest_images = images1[4500:]\ntest_labels = labels1[4500:]","metadata":{"execution":{"iopub.status.busy":"2023-02-09T13:23:58.525084Z","iopub.execute_input":"2023-02-09T13:23:58.525492Z","iopub.status.idle":"2023-02-09T13:23:58.532079Z","shell.execute_reply.started":"2023-02-09T13:23:58.525447Z","shell.execute_reply":"2023-02-09T13:23:58.530741Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Building Neural Net modeling\n","metadata":{}},{"cell_type":"code","source":"num_classes = 12\n\n# build a model using keras layers apis\nmodel = Sequential()\nmodel.add(Conv2D(32, (3,3), activation='relu', input_shape=(120,120,3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32, (3,3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D((2,2)))\n\nmodel.add(Conv2D(64, (3,3), activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, (3,3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D((2,2)))\n\nmodel.add(Conv2D(128, (3,3), activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128, (3,3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D((2,2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(256,activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-02-09T13:23:58.533740Z","iopub.execute_input":"2023-02-09T13:23:58.534425Z","iopub.status.idle":"2023-02-09T13:24:01.125300Z","shell.execute_reply.started":"2023-02-09T13:23:58.534387Z","shell.execute_reply":"2023-02-09T13:24:01.123469Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"2023-02-09 13:23:58.636464: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-09 13:23:58.725442: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-09 13:23:58.726267: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-09 13:23:58.727808: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-02-09 13:23:58.728168: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-09 13:23:58.728858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-09 13:23:58.729515: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-09 13:24:00.611119: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-09 13:24:00.611929: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-09 13:24:00.612627: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-09 13:24:00.613220: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 120, 120, 32)      896       \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 120, 120, 32)      128       \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 118, 118, 32)      9248      \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 118, 118, 32)      128       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 59, 59, 32)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 59, 59, 64)        18496     \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 59, 59, 64)        256       \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 57, 57, 64)        36928     \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, 57, 57, 64)        256       \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 28, 28, 64)        0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 28, 28, 128)       73856     \n_________________________________________________________________\nbatch_normalization_4 (Batch (None, 28, 28, 128)       512       \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 26, 26, 128)       147584    \n_________________________________________________________________\nbatch_normalization_5 (Batch (None, 26, 26, 128)       512       \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 13, 13, 128)       0         \n_________________________________________________________________\nflatten (Flatten)            (None, 21632)             0         \n_________________________________________________________________\ndense (Dense)                (None, 256)               5538048   \n_________________________________________________________________\ndense_1 (Dense)              (None, 12)                3084      \n=================================================================\nTotal params: 5,829,932\nTrainable params: 5,829,036\nNon-trainable params: 896\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# compile the model\nmodel.compile(optimizer='adam',\n             loss='categorical_crossentropy',\n             metrics=['acc'])","metadata":{"execution":{"iopub.status.busy":"2023-02-09T13:24:01.126738Z","iopub.execute_input":"2023-02-09T13:24:01.127115Z","iopub.status.idle":"2023-02-09T13:24:01.141837Z","shell.execute_reply.started":"2023-02-09T13:24:01.127078Z","shell.execute_reply":"2023-02-09T13:24:01.140784Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# y_train and y_test labels\nX_train = train_images\nX_test = test_images\n\ny_train = to_categorical(train_labels, num_classes)\ny_test = to_categorical(test_labels, num_classes)","metadata":{"execution":{"iopub.status.busy":"2023-02-09T13:24:01.143341Z","iopub.execute_input":"2023-02-09T13:24:01.143709Z","iopub.status.idle":"2023-02-09T13:24:01.149433Z","shell.execute_reply.started":"2023-02-09T13:24:01.143673Z","shell.execute_reply":"2023-02-09T13:24:01.148374Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# creating image data gen object\ndatagen = ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True,\n    )\n\n# callbacks\nearly_stop = EarlyStopping(monitor=\"val_acc\",min_delta=0, patience=5,\n                           verbose=0, mode=\"min\", baseline=None, restore_best_weights=True)","metadata":{"execution":{"iopub.status.busy":"2023-02-09T13:42:39.156953Z","iopub.execute_input":"2023-02-09T13:42:39.157962Z","iopub.status.idle":"2023-02-09T13:42:39.164607Z","shell.execute_reply.started":"2023-02-09T13:42:39.157872Z","shell.execute_reply":"2023-02-09T13:42:39.163244Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# fitting model to the data\nhistory = model.fit(datagen.flow(X_train, y_train, batch_size=32),\n         validation_data=datagen.flow(X_test, y_test, batch_size=8),\n         steps_per_epoch=len(X_train) / 32, epochs=20,\n         callbacks = [early_stop]\n         )","metadata":{"execution":{"iopub.status.busy":"2023-02-09T13:42:41.084243Z","iopub.execute_input":"2023-02-09T13:42:41.084596Z","iopub.status.idle":"2023-02-09T13:45:15.807947Z","shell.execute_reply.started":"2023-02-09T13:42:41.084567Z","shell.execute_reply":"2023-02-09T13:45:15.806815Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Epoch 1/20\n140/140 [==============================] - 19s 138ms/step - loss: 0.3577 - acc: 0.8762 - val_loss: 0.4032 - val_acc: 0.8768\nEpoch 2/20\n140/140 [==============================] - 20s 140ms/step - loss: 0.3244 - acc: 0.8887 - val_loss: 1.7493 - val_acc: 0.6266\nEpoch 3/20\n140/140 [==============================] - 19s 135ms/step - loss: 0.3105 - acc: 0.8944 - val_loss: 3.8529 - val_acc: 0.4937\nEpoch 4/20\n140/140 [==============================] - 20s 139ms/step - loss: 0.3160 - acc: 0.8924 - val_loss: 0.5389 - val_acc: 0.8499\nEpoch 5/20\n140/140 [==============================] - 19s 133ms/step - loss: 0.3006 - acc: 0.8993 - val_loss: 1.5128 - val_acc: 0.6574\nEpoch 6/20\n140/140 [==============================] - 19s 138ms/step - loss: 0.2924 - acc: 0.9020 - val_loss: 1.8758 - val_acc: 0.6564\nEpoch 7/20\n140/140 [==============================] - 20s 139ms/step - loss: 0.2727 - acc: 0.8984 - val_loss: 2.0872 - val_acc: 0.6208\nEpoch 8/20\n140/140 [==============================] - 19s 136ms/step - loss: 0.2601 - acc: 0.9164 - val_loss: 1.8113 - val_acc: 0.6689\n","output_type":"stream"}]},{"cell_type":"code","source":"# save the model\nmodel.save(\"seeds_clf.h5\")","metadata":{"execution":{"iopub.status.busy":"2023-02-09T13:49:34.567511Z","iopub.execute_input":"2023-02-09T13:49:34.567876Z","iopub.status.idle":"2023-02-09T13:49:34.737839Z","shell.execute_reply.started":"2023-02-09T13:49:34.567844Z","shell.execute_reply":"2023-02-09T13:49:34.736879Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## Inference","metadata":{}},{"cell_type":"code","source":"# Inference on test data\nmodel.predict(X_test[20:22])","metadata":{"execution":{"iopub.status.busy":"2023-02-09T13:55:44.993882Z","iopub.execute_input":"2023-02-09T13:55:44.994294Z","iopub.status.idle":"2023-02-09T13:55:45.039787Z","shell.execute_reply.started":"2023-02-09T13:55:44.994255Z","shell.execute_reply":"2023-02-09T13:55:45.038821Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"array([[9.4526776e-08, 7.7245273e-02, 4.3788887e-07, 2.1857393e-04,\n        6.9426465e-01, 2.4278812e-05, 3.7250116e-05, 4.2054071e-06,\n        3.9024330e-06, 2.2818887e-01, 1.2399363e-05, 3.8297383e-08],\n       [7.8528722e-18, 8.2241072e-14, 4.4818101e-11, 7.2802415e-28,\n        1.2797480e-02, 2.9625189e-28, 9.8720247e-01, 2.0203455e-22,\n        1.3683995e-13, 4.5306843e-17, 4.8426535e-31, 1.7829757e-22]],\n      dtype=float32)"},"metadata":{}}]}]}