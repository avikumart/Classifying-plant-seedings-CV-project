{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nimport cv2\nimport zipfile\nimport os\nimport glob\nimport shutil\nfrom sklearn.utils import shuffle\n\nimport tensorflow as tf\nimport keras\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import (Conv2D, MaxPooling2D, Flatten, Dense, \n                          Dropout, Rescaling, RandomFlip, RandomRotation, BatchNormalization)\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-10T10:32:45.921345Z","iopub.execute_input":"2023-02-10T10:32:45.922395Z","iopub.status.idle":"2023-02-10T10:32:52.427484Z","shell.execute_reply.started":"2023-02-10T10:32:45.922290Z","shell.execute_reply":"2023-02-10T10:32:52.426163Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Loading the dataset","metadata":{}},{"cell_type":"code","source":"# print the list of labels in folder\nfolder_path = '/kaggle/input/imageclassificationdataset'\nlabels = os.listdir(folder_path)\nlabels","metadata":{"execution":{"iopub.status.busy":"2023-02-10T10:32:52.429220Z","iopub.execute_input":"2023-02-10T10:32:52.429889Z","iopub.status.idle":"2023-02-10T10:32:52.449729Z","shell.execute_reply.started":"2023-02-10T10:32:52.429849Z","shell.execute_reply":"2023-02-10T10:32:52.448563Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"['Scentless Mayweed',\n 'Common wheat',\n 'Charlock',\n 'Black-grass',\n 'Sugar beet',\n 'Loose Silky-bent',\n 'Maize',\n 'Cleavers',\n 'Common Chickweed',\n 'Fat Hen',\n 'Small-flowered Cranesbill',\n 'Shepherd’s Purse']"},"metadata":{}}]},{"cell_type":"code","source":"# path to Black grass images\npath = '/kaggle/input/imageclassificationdataset/Black-grass'\n\nimages = os.listdir(path)\nlen(images)","metadata":{"execution":{"iopub.status.busy":"2023-02-10T10:32:52.451225Z","iopub.execute_input":"2023-02-10T10:32:52.452072Z","iopub.status.idle":"2023-02-10T10:32:52.590588Z","shell.execute_reply.started":"2023-02-10T10:32:52.452034Z","shell.execute_reply":"2023-02-10T10:32:52.589484Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"309"},"metadata":{}}]},{"cell_type":"code","source":"label_count = {}\n\n# path to images folders \nnpath = '/kaggle/input/imageclassificationdataset/'\n\n# run a for loop on labels\nfor label in labels:\n    images_num = len(os.listdir(npath + label))\n    label_count[label] = images_num\n    \nlabel_count","metadata":{"execution":{"iopub.status.busy":"2023-02-10T10:32:52.593877Z","iopub.execute_input":"2023-02-10T10:32:52.594332Z","iopub.status.idle":"2023-02-10T10:32:54.658665Z","shell.execute_reply.started":"2023-02-10T10:32:52.594294Z","shell.execute_reply":"2023-02-10T10:32:54.657590Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"{'Scentless Mayweed': 607,\n 'Common wheat': 253,\n 'Charlock': 452,\n 'Black-grass': 309,\n 'Sugar beet': 463,\n 'Loose Silky-bent': 762,\n 'Maize': 257,\n 'Cleavers': 335,\n 'Common Chickweed': 713,\n 'Fat Hen': 538,\n 'Small-flowered Cranesbill': 576,\n 'Shepherd’s Purse': 274}"},"metadata":{}}]},{"cell_type":"code","source":"# find the total number of  images\nimages_count = 0\nfor value in label_count.values():\n    images_count += value\n    \nprint(images_count)","metadata":{"execution":{"iopub.status.busy":"2023-02-10T10:32:54.660193Z","iopub.execute_input":"2023-02-10T10:32:54.660559Z","iopub.status.idle":"2023-02-10T10:32:54.666106Z","shell.execute_reply.started":"2023-02-10T10:32:54.660508Z","shell.execute_reply":"2023-02-10T10:32:54.665140Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"5539\n","output_type":"stream"}]},{"cell_type":"code","source":"# class labels\nclass_names = ['Scentless Mayweed',\n 'Common wheat',\n 'Charlock',\n 'Black-grass',\n 'Sugar beet',\n 'Loose Silky-bent',\n 'Maize',\n 'Cleavers',\n 'Common Chickweed',\n 'Fat Hen',\n 'Small-flowered Cranesbill',\n 'Shepherd’s Purse']\n\n\nclass_labels = {class_name:i for i, class_name in enumerate(class_names)}\nprint(class_labels)\n\nIMAGE_SIZE = (120,120)","metadata":{"execution":{"iopub.status.busy":"2023-02-10T10:32:54.667578Z","iopub.execute_input":"2023-02-10T10:32:54.668171Z","iopub.status.idle":"2023-02-10T10:32:54.676991Z","shell.execute_reply.started":"2023-02-10T10:32:54.668135Z","shell.execute_reply":"2023-02-10T10:32:54.676016Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"{'Scentless Mayweed': 0, 'Common wheat': 1, 'Charlock': 2, 'Black-grass': 3, 'Sugar beet': 4, 'Loose Silky-bent': 5, 'Maize': 6, 'Cleavers': 7, 'Common Chickweed': 8, 'Fat Hen': 9, 'Small-flowered Cranesbill': 10, 'Shepherd’s Purse': 11}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Labeling the dataset","metadata":{}},{"cell_type":"code","source":"# labeling the dataset\nlabelled_data = []\n\nimages1 = []\nlabels1 = []\n\n\nfor label in labels:\n    lab = class_labels[label]\n    for img in os.listdir(os.path.join('/kaggle/input/imageclassificationdataset/', label)):\n        image_path = os.path.join(os.path.join(npath, label), img)\n        # read the image files\n        img_file = cv2.imread(image_path)\n        img_file = cv2.cvtColor(img_file, cv2.COLOR_BGR2RGB)\n        img_file = cv2.resize(img_file, IMAGE_SIZE)\n        \n        images1.append(img_file)\n        labels1.append(lab)","metadata":{"execution":{"iopub.status.busy":"2023-02-10T10:32:54.678355Z","iopub.execute_input":"2023-02-10T10:32:54.679031Z","iopub.status.idle":"2023-02-10T10:34:19.159872Z","shell.execute_reply.started":"2023-02-10T10:32:54.678996Z","shell.execute_reply":"2023-02-10T10:34:19.158815Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# convert data into np array\nimages1 = np.array(images1, dtype='float32')\nlabels1 = np.array(labels1, dtype='int32')","metadata":{"execution":{"iopub.status.busy":"2023-02-10T10:34:19.161200Z","iopub.execute_input":"2023-02-10T10:34:19.161588Z","iopub.status.idle":"2023-02-10T10:34:19.400971Z","shell.execute_reply.started":"2023-02-10T10:34:19.161526Z","shell.execute_reply":"2023-02-10T10:34:19.399957Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# shuffle the train nad test datasets\n(images1, labels1) = shuffle(images1, labels1, random_state=45)","metadata":{"execution":{"iopub.status.busy":"2023-02-10T10:34:19.402668Z","iopub.execute_input":"2023-02-10T10:34:19.403041Z","iopub.status.idle":"2023-02-10T10:34:19.737851Z","shell.execute_reply.started":"2023-02-10T10:34:19.403002Z","shell.execute_reply":"2023-02-10T10:34:19.736577Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# normalize the iamges\nimages_norm = images1/255.0","metadata":{"execution":{"iopub.status.busy":"2023-02-10T10:34:19.745521Z","iopub.execute_input":"2023-02-10T10:34:19.748132Z","iopub.status.idle":"2023-02-10T10:34:20.038834Z","shell.execute_reply.started":"2023-02-10T10:34:19.748088Z","shell.execute_reply":"2023-02-10T10:34:20.037720Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# train and test split\ntrain_images = images1[:4500]\ntrain_labels = labels1[:4500]\n\ntest_images = images1[4500:]\ntest_labels = labels1[4500:]","metadata":{"execution":{"iopub.status.busy":"2023-02-10T10:34:20.043751Z","iopub.execute_input":"2023-02-10T10:34:20.044238Z","iopub.status.idle":"2023-02-10T10:34:20.053014Z","shell.execute_reply.started":"2023-02-10T10:34:20.044200Z","shell.execute_reply":"2023-02-10T10:34:20.052194Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Building Neural Net model\n","metadata":{}},{"cell_type":"code","source":"num_classes = 12\n\n# build a model using keras layers apis\nmodel = Sequential()\nmodel.add(Conv2D(32, (3,3), activation='relu', input_shape=(120,120,3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32, (3,3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D((2,2)))\n\nmodel.add(Conv2D(64, (3,3), activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, (3,3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D((2,2)))\n\nmodel.add(Conv2D(128, (3,3), activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128, (3,3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D((2,2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(256,activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-02-10T10:34:20.057407Z","iopub.execute_input":"2023-02-10T10:34:20.060320Z","iopub.status.idle":"2023-02-10T10:34:22.850061Z","shell.execute_reply.started":"2023-02-10T10:34:20.060284Z","shell.execute_reply":"2023-02-10T10:34:22.849057Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"2023-02-10 10:34:20.169426: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-10 10:34:20.269319: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-10 10:34:20.270148: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","output_type":"stream"},{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 120, 120, 32)      896       \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 120, 120, 32)      128       \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 118, 118, 32)      9248      \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 118, 118, 32)      128       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 59, 59, 32)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 59, 59, 64)        18496     \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 59, 59, 64)        256       \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 57, 57, 64)        36928     \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, 57, 57, 64)        256       \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 28, 28, 64)        0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 28, 28, 128)       73856     \n_________________________________________________________________\nbatch_normalization_4 (Batch (None, 28, 28, 128)       512       \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 26, 26, 128)       147584    \n_________________________________________________________________\nbatch_normalization_5 (Batch (None, 26, 26, 128)       512       \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 13, 13, 128)       0         \n_________________________________________________________________\nflatten (Flatten)            (None, 21632)             0         \n_________________________________________________________________\ndense (Dense)                (None, 256)               5538048   \n_________________________________________________________________\ndense_1 (Dense)              (None, 12)                3084      \n=================================================================\nTotal params: 5,829,932\nTrainable params: 5,829,036\nNon-trainable params: 896\n_________________________________________________________________\n","output_type":"stream"},{"name":"stderr","text":"2023-02-10 10:34:20.271929: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-02-10 10:34:20.272210: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-10 10:34:20.272967: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-10 10:34:20.273631: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-10 10:34:22.329807: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-10 10:34:22.330762: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-10 10:34:22.331465: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-10 10:34:22.332097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}]},{"cell_type":"code","source":"# compile the model\nmodel.compile(optimizer='adam',\n             loss='categorical_crossentropy',\n             metrics=['acc'])","metadata":{"execution":{"iopub.status.busy":"2023-02-10T10:34:22.851480Z","iopub.execute_input":"2023-02-10T10:34:22.852340Z","iopub.status.idle":"2023-02-10T10:34:22.866747Z","shell.execute_reply.started":"2023-02-10T10:34:22.852301Z","shell.execute_reply":"2023-02-10T10:34:22.865841Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# y_train and y_test labels\nX_train = train_images\nX_test = test_images\n\ny_train = to_categorical(train_labels, num_classes)\ny_test = to_categorical(test_labels, num_classes)","metadata":{"execution":{"iopub.status.busy":"2023-02-10T10:34:22.868821Z","iopub.execute_input":"2023-02-10T10:34:22.869545Z","iopub.status.idle":"2023-02-10T10:34:22.874985Z","shell.execute_reply.started":"2023-02-10T10:34:22.869507Z","shell.execute_reply":"2023-02-10T10:34:22.873916Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# creating image data gen object\ndatagen = ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True,\n    )\n\n# callbacks\nearly_stop = EarlyStopping(monitor=\"val_acc\",min_delta=0, patience=5,\n                           verbose=0, mode=\"min\", baseline=None, restore_best_weights=True)","metadata":{"execution":{"iopub.status.busy":"2023-02-10T10:34:22.876530Z","iopub.execute_input":"2023-02-10T10:34:22.876953Z","iopub.status.idle":"2023-02-10T10:34:22.887906Z","shell.execute_reply.started":"2023-02-10T10:34:22.876898Z","shell.execute_reply":"2023-02-10T10:34:22.886996Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# fitting model to the data\nhistory = model.fit(datagen.flow(X_train, y_train, batch_size=32),\n         validation_data=datagen.flow(X_test, y_test, batch_size=8),\n         steps_per_epoch=len(X_train) / 32, epochs=20,\n         callbacks = [early_stop]\n         )","metadata":{"execution":{"iopub.status.busy":"2023-02-10T10:41:26.481307Z","iopub.execute_input":"2023-02-10T10:41:26.481707Z","iopub.status.idle":"2023-02-10T10:44:20.902506Z","shell.execute_reply.started":"2023-02-10T10:41:26.481675Z","shell.execute_reply":"2023-02-10T10:44:20.901594Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n  warnings.warn('This ImageDataGenerator specifies '\n/opt/conda/lib/python3.7/site-packages/keras_preprocessing/image/image_data_generator.py:728: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n  warnings.warn('This ImageDataGenerator specifies '\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20\n140/140 [==============================] - 20s 140ms/step - loss: 1.7026 - acc: 0.4691 - val_loss: 1.5415 - val_acc: 0.5111\nEpoch 2/20\n140/140 [==============================] - 19s 135ms/step - loss: 1.2278 - acc: 0.5898 - val_loss: 1.7869 - val_acc: 0.4832\nEpoch 3/20\n140/140 [==============================] - 19s 132ms/step - loss: 1.0274 - acc: 0.6560 - val_loss: 0.9784 - val_acc: 0.6756\nEpoch 4/20\n140/140 [==============================] - 19s 135ms/step - loss: 0.8429 - acc: 0.7111 - val_loss: 2.0397 - val_acc: 0.4331\nEpoch 5/20\n140/140 [==============================] - 20s 141ms/step - loss: 0.7508 - acc: 0.7478 - val_loss: 1.1562 - val_acc: 0.6266\nEpoch 6/20\n140/140 [==============================] - 19s 138ms/step - loss: 0.6986 - acc: 0.7600 - val_loss: 0.9076 - val_acc: 0.7036\nEpoch 7/20\n140/140 [==============================] - 20s 143ms/step - loss: 0.6665 - acc: 0.7762 - val_loss: 1.5943 - val_acc: 0.5140\nEpoch 8/20\n140/140 [==============================] - 19s 134ms/step - loss: 0.6269 - acc: 0.7858 - val_loss: 1.6772 - val_acc: 0.4937\nEpoch 9/20\n140/140 [==============================] - 20s 140ms/step - loss: 0.5832 - acc: 0.8038 - val_loss: 1.4293 - val_acc: 0.5621\n","output_type":"stream"}]},{"cell_type":"code","source":"# save the model\nmodel.save(\"seeds_clf.h5\")","metadata":{"execution":{"iopub.status.busy":"2023-02-10T10:36:27.295739Z","iopub.execute_input":"2023-02-10T10:36:27.296087Z","iopub.status.idle":"2023-02-10T10:36:27.459874Z","shell.execute_reply.started":"2023-02-10T10:36:27.296050Z","shell.execute_reply":"2023-02-10T10:36:27.458902Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## Inference","metadata":{}},{"cell_type":"code","source":"# Inference on test data\npreds = model.predict(X_test[20:22])\npredictions = np.argmax(preds, axis=1)\npredictions","metadata":{"execution":{"iopub.status.busy":"2023-02-10T10:46:49.323319Z","iopub.execute_input":"2023-02-10T10:46:49.323701Z","iopub.status.idle":"2023-02-10T10:46:49.370735Z","shell.execute_reply.started":"2023-02-10T10:46:49.323662Z","shell.execute_reply":"2023-02-10T10:46:49.369816Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"array([8, 8])"},"metadata":{}}]},{"cell_type":"markdown","source":"## Conclusion:\n\n1) We loaded the dataset and assigned numerical labels to each images\n\n2) We converted images into numpy arrays to build neural network model\n\n3) We developed NN model and trained using data augmentation\n\n4) Tested model on test dataset and inference using `predict()` method.","metadata":{}}]}